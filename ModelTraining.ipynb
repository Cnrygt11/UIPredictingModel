{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "JCB7wzXTR--C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense"
      ],
      "metadata": {
        "id": "zXRqVpWqzsMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ana veri klasörü\n",
        "base_dir = 'drive/MyDrive/myData'\n",
        "# Alt klasörler (sınıflar)\n",
        "class_folders = ['buttons', 'dropdowns', 'textboxes', 'checkboxes', 'radioboxes']"
      ],
      "metadata": {
        "id": "LvTMHXNTpiVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resimleri grayscale yapan kod parçası, ancak kullanılmadı.\n",
        "for filename in os.listdir(base_dir):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):  # Resim formatlarını kontrol et\n",
        "        img_path = os.path.join(base_dir, filename)  # Tam dosya yolunu oluştur\n",
        "        img = Image.open(img_path).convert('L')  # Resmi aç ve grayscale'e çevir\n",
        "        img.save(img_path)  # Aynı isimle kaydet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtEyk2QUJ5Sh",
        "outputId": "62c342f3-cf34-4f45-e2cf-c6691d3c189f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tüm resimler grayscale yapıldı.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('myData/train', exist_ok=True)\n",
        "os.makedirs('myData/val', exist_ok=True)\n",
        "os.makedirs('myData/test', exist_ok=True)"
      ],
      "metadata": {
        "id": "mAw5sJc7z5Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for class_folder in class_folders:\n",
        "    # Her sınıf için dizinler oluştur\n",
        "    os.makedirs(f'myData/train/{class_folder}', exist_ok=True)\n",
        "    os.makedirs(f'myData/val/{class_folder}', exist_ok=True)\n",
        "    os.makedirs(f'myData/test/{class_folder}', exist_ok=True)\n",
        "\n",
        "    # Sınıf klasöründeki tüm resimleri listele\n",
        "    img_files = [f for f in os.listdir(os.path.join(base_dir, class_folder)) if os.path.isfile(os.path.join(base_dir, class_folder, f))]\n",
        "\n",
        "    # Eğitim, doğrulama ve test setlerine ayır\n",
        "    train_files, temp_files = train_test_split(img_files, test_size=0.30, random_state=42)\n",
        "    val_files, test_files = train_test_split(temp_files, test_size=0.33, random_state=42)\n",
        "\n",
        "    # Dosyaları uygun klasörlere kopyala\n",
        "    for file_name in train_files:\n",
        "        shutil.copy(os.path.join(base_dir, class_folder, file_name), os.path.join('myData/train', class_folder, file_name))\n",
        "    for file_name in val_files:\n",
        "        shutil.copy(os.path.join(base_dir, class_folder, file_name), os.path.join('myData/val', class_folder, file_name))\n",
        "    for file_name in test_files:\n",
        "        shutil.copy(os.path.join(base_dir, class_folder, file_name), os.path.join('myData/test', class_folder, file_name))\n",
        "\n",
        "print(\"Veri seti başarıyla bölündü ve dosyalar kopyalandı.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46_vkGNh0A2W",
        "outputId": "35f1bb7e-385d-4cd2-8673-d9782346793e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Veri seti başarıyla bölündü ve dosyalar kopyalandı.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_path = 'myData/train'\n",
        "data_test_path = 'myData/test'\n",
        "data_val_path = 'myData/val'"
      ],
      "metadata": {
        "id": "VpuABVFa1et2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width = 128\n",
        "img_height = 256"
      ],
      "metadata": {
        "id": "gswZx34p1vb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    fill_mode='nearest',\n",
        ")\n",
        "\n",
        "\n",
        "data_train = train_datagen.flow_from_directory(\n",
        "    data_train_path,\n",
        "    shuffle = True,\n",
        "    target_size = (img_width, img_height),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical',\n",
        "    #color_mode='grayscale'\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXMatHPc14in",
        "outputId": "fa7228e5-7b14-4f82-98c3-80441c6c2109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1855 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_cat = data_train.class_indices\n",
        "data_cat = {v: k for k, v in data_cat.items()}\n",
        "data_cat"
      ],
      "metadata": {
        "id": "ypBGtv96YlLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "data_val = val_test_datagen.flow_from_directory(\n",
        "    data_val_path,\n",
        "    shuffle = False,\n",
        "    target_size = (img_width, img_height),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical',\n",
        "    #color_mode='grayscale'\n",
        "    )"
      ],
      "metadata": {
        "id": "6falpdGz2tPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = val_test_datagen.flow_from_directory(\n",
        "    data_test_path,\n",
        "    shuffle = False,\n",
        "    target_size = (img_width, img_height),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical'\n",
        "    )"
      ],
      "metadata": {
        "id": "kqGinFoP3Orz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Önceki denemeler bu model üzerinden yapıldı\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(img_width, img_height, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "FyYIahglRPsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f824dce5-dfd6-40ff-f820-bbf1272be450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))"
      ],
      "metadata": {
        "id": "CXgbqPBER-s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    base_model,               # Önceden eğitilmiş modelin eklenmesi\n",
        "    Flatten(),                # Veriyi düzleştir\n",
        "    Dense(512, activation='relu'),  # İlk dense katman (512 nöron)\n",
        "    Dropout(0.5),             # %50 dropout\n",
        "    Dense(256, activation='relu'),  # İkinci dense katman (256 nöron)\n",
        "    Dropout(0.5),             # %50 dropout\n",
        "    Dense(5, activation='softmax')  # Çıkış katmanı (5 sınıf)\n",
        "])"
      ],
      "metadata": {
        "id": "JnA1AhKBSZmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0005),  # Adam optimizasyon algoritması\n",
        "    loss='categorical_crossentropy',       # Kategorik çapraz entropi kaybı\n",
        "    metrics=['accuracy']                   # Doğruluk metriği\n",
        ")"
      ],
      "metadata": {
        "id": "eeyPKkKBSvCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Kullanılmadı\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3)"
      ],
      "metadata": {
        "id": "EZ_IJrdxS5Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    data_train,\n",
        "    epochs=50,\n",
        "    validation_data=data_val,\n",
        ")"
      ],
      "metadata": {
        "id": "do9-H_GzS94C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(data_test)\n",
        "\n",
        "print(f\"Loss: {test_loss}\")\n",
        "print(f\"Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "BIwAgAQ_KDcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = 'g.png'\n",
        "image = tf.keras.utils.load_img(image, target_size=(img_width, img_height))\n",
        "img_arr = tf.keras.utils.img_to_array(image)\n",
        "img_bat = tf.expand_dims(img_arr, 0)\n",
        "\n",
        "predict = model.predict(img_bat)\n",
        "\n",
        "score = tf.nn.softmax(predict[0])\n",
        "\n",
        "print('This belongs to {} class, accuracy: {:0.2f}'.format(data_cat[np.argmax(score)], 100 * np.max(score)))"
      ],
      "metadata": {
        "id": "0nsSyhCA-lGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.keras')"
      ],
      "metadata": {
        "id": "ij_Bh2zoS_cO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
